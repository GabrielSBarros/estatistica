---
title: "Trabalho de Estatística"
output: html_document
---

```{r echo = FALSE, message = FALSE} 
  data = read.csv("USvideos.csv")
  attach(data)
```

```{r echo = FALSE}

```

```{r}

```

# Escolha da Base de Dados

### Para a base de dados, foram escolhidas informações sobre vídeos "em alta" do YouTube (i.e. vídeos de destaque na plataforma, postos em uma aba diferenciada). Para a análise, escolhemos vídeos do YouTube estadunidense. A base encontra-se no formato CSV, e utilizamos o software estatístico R para efetuar os comandos de maneira adequada.

### A base é composta de 40949 vídeos, publicados desde 2006 até 2018, onde todos em determinado momento foram incluídos na aba "em-alta", e possui as seguintes variáveis: 

### identificador do vídeo, data em que entrou na aba "em alta", título do vídeo, título do canal que o publicou, identificador da categoria do vídeo, data e hora de publicação do vídeo, tags do vídeo, visualizações do vídeo, número de "gosteis", número de "não gosteis", contagem de comentários, link da imagem de thumbnail do vídeo, descrição do vídeo e valores chaveados que dizem se os comentários foram desabilitados, a avaliação do vídeo ("gosteis" e "não gosteis") foram desabilitados, e por fim se ocorreu algum erro no vídeo ou se foi deletado.

### Na pesquisa efetuada sobre esta base de dados, buscamos analisar a dependência das visualizações de um vídeo com a quantidade de "gosteis", quantidade de "não gosteis", contagem de comentário, se o vídeo permite comentários e se permite avaliações.

# Análise Descritiva

## Interpretação das Dispersões

```{r message = FALSE}
  attach(data)
  plot(views, likes)
```

### Acima, efetuamos um gráfico de dispersão para as variávies Visualizações e "Gosteis" dos vídeos. Dado o grande número de observações agrupada com menores visualizações e números de likes, o gráfico tem sua legibilidade dificultada. Para melhorar a sua leitura, efetuamos um gráfico de dispersão normalmente, porém desta vez com uma amostra reduzida de vídeos com até 1 milhão de visualizações.

```{r echo = FALSE, message = FALSE}
  amostra <- data[views < 1000000,]
  attach(amostra)
  plot(views[0:500], likes[0:500], xlim=c(0, 1500000), ylim=c(0,75000), xlab ="Visualizações", ylab="Número de likes", main = "Dispersão das views")
```

### Com esta redução nas observações, podemos ver melhor o seu comportamento no que diz respeito a estas variáveis. Pode-se ver que há uma dispersão gradual dos vídeos à medida que o número de visualizações aumenta, pois vídeos de menos visualizações têm menos likes. Esses vídeos com menores visualizações agrupam-se bastante próximos entre si, o que evidencia que a base de dados é composta por um grande número de outliers. Ainda assim, visto que há uma tendência de que vídeos com mais visualizações tenham maiores likes, podemos começar a ver indícios de correlação entre ambas as variáveis.

```{r message = FALSE}
  attach(data)
  plot(views, comment_count)
```

### Fizemos o mesmo para Número de Comentários e Visualizações. Assim como no gráfico de dispersão inicial para as variáveis anteriores, este possui uma grande concentração de observações com poucos comentários e poucas visualizações. Utilizamos a mesma estratégia, utilizando a mesma amostra limitada anteriormente.

```{r echo = FALSE, message = FALSE}
  attach(amostra)
  plot(views[0:500], comment_count[0:500], xlim=c(0, 2000000), ylim=c(0,20000), xlab = "Visualizações", ylab="Comentários", main = "Dispersão das views")
```

### Podemos ver com este gráfico mais controlado que as observações têm uma maior dispersão entre si que no gráfico de Visualizações vs Likes. Isso nos oferece uma pista de que a correlação entre Comentários e Visualizações pode ser menor que Visualizações e Likes.

## Análise das Correlações

### Então, para averiguar mais adequadamente a correlação das variáveis da base de dados, efetuamos os testes abaixo. Pode-se observar que a correlação entre Visualizações e Likes é forte, visto que possui um valor entre 0,70 e 0,89; porém, quanto a Visualizações e Comentários a correlação é moderada, com um valor entre 0,40 e 0,69, colaborando com nossas investigações anteriores. 

```{r}
  cor(views, likes)
  cor(views, comment_count)
```

## Análise de Distribuição

### Abaixo, expressamos um bloxplot das Visualizações com o objetivo de analisar um pouco mais a distribuição das observações. Vemos aqui que a mediana tem o valor baixo de 681861, porém que está bem abaixo no boxplot; através disto, pode-se ver que a distribuição dos dados não é 'comportada'. Adicionalmente, podemos confirmar a quantidade vasta de outliers, isto é, visitas com números extraordinários de visualizações. 

```{r echo = FALSE, message = FALSE}
  attach(data)
```

```{r message = FALSE}
  views_count <- subset(data[8], data[8] < 4000000)
  boxplot(views_count, col = 'lightblue', main = "Boxplot das views da aba Em alta")
```

### Os dois gráficos abaixo referem-se à proporção de vídeos com habilitação de comentários, e às quantidades de vídeos enquadrados nas diferentes categorias. Pelo gráfico de setores, podemos observar que a grande maioria dos vídeos em alta têm comentários habilitados; já pelo gráfico gráfico de barras, podemos observar que a maior parte dos vídeos em alta pertencem à categoria "entretenimento", seguida pela categoria "música".

```{r}
  freq <- table(comments_disabled)
  pie(freq, main = "Habilitação de comentários", labels = c("98.45%", "1.55%"), col=c(4,2))
  legend("topright", fill = c(4,2), legend = c("Habilitados", "Desativados"))
```

```{r}
  ajustes <- table(data$category_id)
  barplot(ajustes, col = "lightblue", main = "Número de ocorrências de vídeos por categoria",     ylab = "Frequência", xlab = "Id da categoria")
  legend("topright", c("10: Música","22: Vlogs ","23: Comédia", "24: Entretenimento", "26: Moda", "27: Educação"), bty = "n")
```

# Modelo e Teste para Regressão

### Agora, analisadas que há correlação entre "gosteis", "não gosteis" e contagem de comentários para com as visualizações, buscamos montar um modelo de regressão linear múltipla que possui a seguinte formulação: 

### Visualizações = B0 + B1 * ("Gosteis") + B2 ("Não Gosteis") + B3 * (Contagem de Comentários) + B4 * (Comentários Habilitados) + B5 * (Avaliações Habilitadas)

```{r}
frame <- data.frame(views = views, likes = likes, dislikes = dislikes, comment_count = comment_count, comments_disabled = comments_disabled, ratings_disabled = ratings_disabled)
full.model <- lm(views~. , data = frame)
anova(full.model)
```

### Com o modelo configurado, efetuamos o teste ANOVA para analisar se há regressão. Na tabela, podemos observar algo interessante: o valor-p para cada variável é 2,2 * 10^(-16); este não é só um valor bastante pequeno, como também é o menor valor acima de 0 que o R consegue computar e representar em formato decimal (double, ou dupla precisão). Isto nos sugere que o valor-p é tão pequeno que representa que as variáveis são significativas até para uma pesquisa com alfa=0,0; em outras palavras, para uma pesquisa com nível de significância 0,0.

### Podemos em seguida observar os valores F de cada variável. O valor enorme para a variável "gosteis" sugere que a mesma possui um impacto enorme no modelo, enquanto que o fato de comentários estarem habilitados impacta muito menos (isto porque, provavelmente, a grande massa de vídeos em alta está com os comentários habilitados, fazendo com que a existência da variável em si não seja muito relevante).

### Em luz destas informações, podemos concluir com propriedade que há regressão, e que as variáveis independentes de fato influenciam a variável Visualizações e que de fato compõem uma função linear. Portanto, damos seguimento ao experimento.

```{r}
 library(MASS)
 step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
 summary(step.model)
```

### Em seguida, efetuamos o método stepwise de escolha para o melhor modelo. Estranhamente, o método stepwise não sugeriu mudança alguma no modelo prévio, apenas replicando-o.

# Teste de Hipótese Marginal
```{r}
  modelo1 = lm(views ~ likes + dislikes + comment_count + comments_disabled + ratings_disabled)
  modelo2 = lm(views ~ likes + dislikes + comment_count)
```

## Modelo 1

```{r}
  summary(modelo1)
```

## Modelo 2

```{r}
  summary(modelo2)
```

### Visto que na tabela ANOVA do modelo anterior nós presenciamos que os valores F mais baixos pertenciam às variáveis Comentários Habilitados e Avaliações Habilitadas, criamos um modelo alternativo sem estas duas variáveis, e buscamos compará-los a seguir.

### Efetuando o teste de hipótese marginal para cada parâmetro beta em ambos os modelos, podemos observar que no primeiro modelo, todas as variáveis - com exceção de Comentários Habilitados - possuem o menor valor-p representável, tornando-as todas relevantes. Quanto ao segundo modelo, de maneira quase idêntica, todas as variáveis possuem o menor valor-p representável. Desta maneira, nos resta tomar como critério de decisão utilizar o R² (ou coeficiente de determinação). Podemos observar que ambos os modelos conseguem explicar a maioria das observações de visualizações, porém que o primeiro modelo tem maior coeficiente; assim, escolhemos o primeiro modelo como o melhor modelo até então.

### É interessante notar que, embora tenhamos julgado que as variáveis Comentários Habilitados e Avaliações Habilitadas pouco importassem para o modelo, elas na realidade colaboram com a melhoria do componente determinístico do modelo, tornando-o melhor.

# Análise de Resíduos

## Modelo 1

```{r}
  shapiro.test(residuals(modelo1)[0:4500])
```

### Seguimos então para a validação das pressuposições de um modelo de regressão linear, que consiste em testar se os resíduos comportam-se de maneira esperada.

### Iniciamos com o teste Shapiro-Wilk de normalidade dos resíduos (i.e. se os resíduos do modelo seguem uma distribuição normal). Limitamos o tamanho da amostra para 4500 observações, dada uma limitação do teste em R. Para nossa decepção, tivemos o infortúnio de que o teste Shapiro-Wilk entregasse-nos um valor-p baixíssimo: o menor valor-p representável, o que nos causou estranheza. Visto que o valor-p é baixíssimo, não é possível aceitar a hipótese H0 de que os resíduos seguem uma distribuição normal, fazendo com que as pressuposições de um modelo de regressão linear sejam quebradas; consequentemente, o modelo não é confiável.

```{r}
  qqnorm(residuals(modelo1), ylab="Resíduos", xlab = "Quantis Teóricos")
  qqline(residuals(modelo1))
```

### Para checar o resultado do valor-p retornado pelo teste Shapiro-Wilk, efetuamos um gráfico de Resíduos vs Quantis Teóricos, onde podemos observar sinuosidade no gráfico, mostrando uma grande variabilidade nos resíduos, que destoa bastante do comportamento teórico expresso na linha.


## Modelo 2

### Visto que o primeiro modelo foi então rejeitado pelo teste das pressuposições na análise residual, nos restou analisar o segundo modelo visto anteriormente. Efetuando o teste Shapiro-Wilk também neste segundo modelo, podemos ver um comportamento muito similar nos resíduos, o que invalida também este segundo modelo.

```{r}
  shapiro.test(residuals(modelo2)[0:4500])
```

```{r}
  qqnorm(residuals(modelo2), ylab="Resíduos", xlab = "Quantis Teóricos")
  qqline(residuals(modelo2))
```

# Algoritmo de Seleção dos Vídeos em Alta

### Para um vídeo entrar na aba em alta, o algoritmo leva em consideração muitos sinais, incluindo (mas não limitados a):

### - Contagem de visualizações
### - A taxa de crescimento em visualizações
### - De onde vêm as visualizações (incluindo fora do YouTube)
### - A data de publicação do vídeo (quanto mais recente, maior é a chance de entrar na aba em alta)

### Esse algoritmo é automático, no entanto, também é verificado se os vídeos sugeridos pelo algoritmo são:

### - Atraentes para uma ampla gama de espectadores
### - Não enganosas, clickbaits ou sensacionalistas
### - Surpreendentes, novos e originais

### Essa etapa é feita manualmente pelos funcionários do YouTube.

# Conclusão

### Após todos os testes foi observado que os modelos propostos de regressão linear múltipla não são válidos, visto que as pressuposições para que os mesmos ocorram não são satisfeitas. Nos estranhou, inicialmente, o comportamento que os resíduos apresentam. Entretanto, ao analisar mais profundamente o procedimento efetuado pelo YouTube para que um vídeo da plataforma entre na aba "em alta", podemos ver que não apenas há o componente automatizado, como também há uma forte influência manual humana de uma equipe de curadoria do YouTube, como melhor descrito na seção acima. Desta maneira, acreditamos que parte da componente residual do modelo de regressão linear se dá graças à interferência humana nas seleções dos vídeos.

# Referências

### Documentação do algoritmo do YouTube:
### https://support.google.com/youtube/answer/7239739?hl=en
### ----------------------------------------------------------------------------------------
### Documentação das categorias de vídeo no YouTube
### https://gist.github.com/dgp/1b24bf2961521bd75d6c
### ----------------------------------------------------------------------------------------
### Base de dados utilizada:
### https://www.kaggle.com/datasnaek/youtube-new

<style type="text/css">
h1 {
}

h2 {
  font-size: 2.8vh;
}

h3 {
  font-size: 2.3vh;
}
</style>
